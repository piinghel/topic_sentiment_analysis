{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"C:\\\\Users\\\\Pieter-Jan\\\\Documents\\\\Work\\\\Candriam\\\\nlp\\\\ESG\\\\topic_sentiment_analysis\"\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulations\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import sparse\n",
    "\n",
    "# CMT\n",
    "from contextualized_topic_models.models.ctm import CTM\n",
    "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file, TextHandler\n",
    "from contextualized_topic_models.datasets.dataset import CTMDataset\n",
    "from contextualized_topic_models.evaluation.measures import CoherenceNPMI, InvertedRBO, CoherenceWordEmbeddings\n",
    "from contextualized_topic_models.utils.preprocessing import SimplePreprocessing\n",
    "\n",
    "# lDA\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import LdaMulticore \n",
    "import pyLDAvis.gensim\n",
    "from gensim import corpora, matutils, models, similarities\n",
    "import pyLDAvis\n",
    "\n",
    "# BerTopic\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# other\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PyPDF2\n",
    "from pdfminer.high_level import extract_text\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# own modules\n",
    "import modules.preprocessing as preprocess"
   ]
  },
  {
   "source": [
    "# Goal\n",
    "\n",
    "We are going to compare the performance of three **unsupervised** models for topic modelling on 50 corperate governance documents.\n",
    "\n",
    "1. Contextualized Topic Modelling (CTM): https://github.com/MilaNLProc/contextualized-topic-models\n",
    "2. Latent Dirichlet Allocation (LDA): https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "3. BERTopic: https://github.com/MaartenGr/BERTopic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation measures \n",
    "\n",
    "1. **Normalized Point-wise Mutual Information (NPMI) (Lau et al.,\n",
    "2014)**\n",
    "\n",
    "It measures how much the top-10 words of a topic are related to each other, considering the empirical frequency of the words computed on the\n",
    "original corpus. τ is a symbolic metric and relies on co-occurrence.\n",
    "\n",
    "2. **External Word Embeddings Topic Coherence**\n",
    "\n",
    "As Ding et al. (2018) pointed out, though, topic\n",
    "coherence computed on the same data is inherently\n",
    "limited. Coherence computed on an external corpus, on the other hand, correlates much more to\n",
    "human judgment, but it may be expensive to estimate. Thus, our second metric is an external\n",
    "word embeddings topic coherence metric, which we compute by adopting a strategy similar to that\n",
    "described in Ding et al. (2018). First, we compute\n",
    "the average pairwise cosine similarity of the word\n",
    "embeddings of the top-10 words in a topic using (Mikolov et al., 2013) embeddings. Then, we\n",
    "compute the overall average of those values for all\n",
    "the topics (α).\n",
    "\n",
    "3. **rank-\n",
    "biased overlap (RBO) (Webber et al., 2010)**\n",
    "\n",
    "To evaluate how diverse the topics\n",
    "generated by a single model are, we use the rank-\n",
    "biased overlap (RBO) (Webber et al., 2010). RBO\n",
    "compares two topics of the same model. The key\n",
    "qualities of this measure are twofold: it allows\n",
    "disjointedness between the lists of topics (i.e., two\n",
    "topics can have different words in them) and it is\n",
    "weighted on the ranking (i.e., two lists that share\n",
    "some of the same words, albeit at different rankings,\n",
    "are penalized less than two lists that share the same\n",
    "words at the highest ranks). We deﬁne ρ as the rank-\n",
    "biased overlap diversity, that we interpret as the\n",
    "reciprocal of the standard RBO. ρ is 0 for identical\n",
    "topics and 1 for completely different topics. Both\n",
    "metrics are computed on the top-k ranked lists.\n",
    "Following the state-of-the-art, we consider k = 10."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Read in reports and perform some text processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation measures \n",
    "\n",
    "1. **Normalized Point-wise Mutual Information (NPMI) (Lau et al.,\n",
    "2014)**\n",
    "\n",
    "It measures how much the top-10 words of a topic are related to each other, considering the empirical frequency of the words computed on the\n",
    "original corpus. τ is a symbolic metric and relies on co-occurrence.\n",
    "\n",
    "2. **External Word Embeddings Topic Coherence**\n",
    "\n",
    "As Ding et al. (2018) pointed out, though, topic\n",
    "coherence computed on the same data is inherently\n",
    "limited. Coherence computed on an external corpus, on the other hand, correlates much more to\n",
    "human judgment, but it may be expensive to estimate. Thus, our second metric is an external\n",
    "word embeddings topic coherence metric, which we compute by adopting a strategy similar to that\n",
    "described in Ding et al. (2018). First, we compute\n",
    "the average pairwise cosine similarity of the word\n",
    "embeddings of the top-10 words in a topic using (Mikolov et al., 2013) embeddings. Then, we\n",
    "compute the overall average of those values for all\n",
    "the topics (α).\n",
    "\n",
    "3. **rank-\n",
    "biased overlap (RBO) (Webber et al., 2010)**\n",
    "\n",
    "To evaluate how diverse the topics\n",
    "generated by a single model are, we use the rank-\n",
    "biased overlap (RBO) (Webber et al., 2010). RBO\n",
    "compares two topics of the same model. The key\n",
    "qualities of this measure are twofold: it allows\n",
    "disjointedness between the lists of topics (i.e., two\n",
    "topics can have different words in them) and it is\n",
    "weighted on the ranking (i.e., two lists that share\n",
    "some of the same words, albeit at different rankings,\n",
    "are penalized less than two lists that share the same\n",
    "words at the highest ranks). We deﬁne ρ as the rank-\n",
    "biased overlap diversity, that we interpret as the\n",
    "reciprocal of the standard RBO. ρ is 0 for identical\n",
    "topics and 1 for completely different topics. Both\n",
    "metrics are computed on the top-k ranked lists.\n",
    "Following the state-of-the-art, we consider k = 10."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Pieter-Jan\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-3-010f4a6c95ad>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-010f4a6c95ad>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    DIR_REPORTS = '\"C:/Users/Pieter-Jan/Documents/Work/Candriam/nlp/ESG/reports/Corporate_Governance_Report\" global variable used throughout te notebook to update preprocessing steps\u001b[0m\n\u001b[1;37m                                                                                                                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "UPDATE = False\n",
    "DIR_REPORTS = '\"C:/Users/Pieter-Jan/Documents/Work/Candriam/nlp/ESG/reports/Corporate_Governance_Report\" global variable used throughout te notebook to update preprocessing steps\n",
    "UPDATE = True\n",
    "DIR_REPORTS = \"C:/Users/Pieter-Jan/Documents/Work/Candriam/nlp/ESG/reports/Corporate_Governance_Report\""
   ]
  },
  {
   "source": [
    "## Download reports and perform some text processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "bjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:53>, 'F3': <PDFObjRef:63>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:19>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.478 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:53>, 'F3': <PDFObjRef:63>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.481 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:53>, 'F3': <PDFObjRef:63>}}, streams=[<PDFStream(19): raw=1337, {'Filter': /'FlateDecode', 'Length': 1336}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.540 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:53>, 'F3': <PDFObjRef:63>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:20>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.542 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:53>, 'F3': <PDFObjRef:63>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.544 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:53>, 'F3': <PDFObjRef:63>}}, streams=[<PDFStream(20): raw=1514, {'Filter': /'FlateDecode', 'Length': 1513}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.606 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:21>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.608 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.610 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, streams=[<PDFStream(21): raw=1293, {'Filter': /'FlateDecode', 'Length': 1292}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.679 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:63>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:22>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.682 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:63>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.686 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:63>}}, streams=[<PDFStream(22): raw=1155, {'Filter': /'FlateDecode', 'Length': 1154}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.731 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:63>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:23>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.734 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:63>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.737 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:63>}}, streams=[<PDFStream(23): raw=1088, {'Filter': /'FlateDecode', 'Length': 1087}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.787 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:53>, 'F2': <PDFObjRef:58>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:24>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.789 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:53>, 'F2': <PDFObjRef:58>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.792 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:53>, 'F2': <PDFObjRef:58>}}, streams=[<PDFStream(24): raw=1641, {'Filter': /'FlateDecode', 'Length': 1640}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.863 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:25>, 'Parent': <PDFObjRef:84>}\n",
      "2020-11-17 23:42:23.867 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.870 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, streams=[<PDFStream(25): raw=999, {'Filter': /'FlateDecode', 'Length': 998}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:23.940 INFO    pdfminer.pdfpage: Pages: Kids=[<PDFObjRef:94>, <PDFObjRef:95>, <PDFObjRef:96>, <PDFObjRef:109>, <PDFObjRef:110>]\n",
      "2020-11-17 23:42:23.942 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:26>, 'Parent': <PDFObjRef:93>}\n",
      "2020-11-17 23:42:23.945 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:23.947 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, streams=[<PDFStream(26): raw=1130, {'Filter': /'FlateDecode', 'Length': 1129}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:24.001 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:27>, 'Parent': <PDFObjRef:93>}\n",
      "2020-11-17 23:42:24.003 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:24.005 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>}}, streams=[<PDFStream(27): raw=1189, {'Filter': /'FlateDecode', 'Length': 1188}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:24.072 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>, 'G1': <PDFObjRef:97>, 'G2': <PDFObjRef:98>}, 'XObject': {'X0': <PDFObjRef:28>, 'X1': <PDFObjRef:30>, 'X2': <PDFObjRef:32>, 'X3': <PDFObjRef:34>, 'X4': <PDFObjRef:36>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:99>, 'F2': <PDFObjRef:104>}}, 'MediaBox': [0, 0, 611, 791], 'Annots': [{'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [230.5, 461.25, 319, 500.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/investors/resources/printed-material-request.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [230.5, 407.25, 319, 435.75], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/investors/resources/setup-email-alerts.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [120.25, 223.5, 179.5, 239.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/consumer.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [120.25, 162, 195.25, 204], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/for-healthcare-professionals.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [120.25, 100.5, 189.25, 116.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/about-abbott.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [229.75, 223.5, 271.75, 239.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/careers.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [229.75, 188.25, 280.75, 204], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/investors.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [229.75, 153, 286.75, 168.75], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/corpnewsroom.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [229.75, 117.75, 292, 133.5], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/lifetothefullest.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [229.75, 82.5, 285.25, 98.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/about-abbott/abbott-citizenship.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [339.25, 223.5, 379.75, 239.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/site-map.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [339.25, 188.25, 380.5, 204], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/policies.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [339.25, 153, 383.5, 168.75], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/contact.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [339.25, 117.75, 401.5, 133.5], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/global-sites.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [339.25, 82.5, 414.25, 98.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/privacy-policy.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [448.75, 173.25, 466, 190.5], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'https://www.facebook.com/Abbott'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [490, 173.25, 507.25, 190.5], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://instagram.com/abbottglobal'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [460.75, 138.75, 478, 155.25], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'https://www.youtube.com/c/abbott'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [448.75, 102.75, 466, 120], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.linkedin.com/company/1612'}}], 'Contents': <PDFObjRef:38>, 'Parent': <PDFObjRef:93>}\n",
      "2020-11-17 23:42:24.075 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>, 'G1': <PDFObjRef:97>, 'G2': <PDFObjRef:98>}, 'XObject': {'X0': <PDFObjRef:28>, 'X1': <PDFObjRef:30>, 'X2': <PDFObjRef:32>, 'X3': <PDFObjRef:34>, 'X4': <PDFObjRef:36>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:99>, 'F2': <PDFObjRef:104>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:24.077 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>, 'G1': <PDFObjRef:97>, 'G2': <PDFObjRef:98>}, 'XObject': {'X0': <PDFObjRef:28>, 'X1': <PDFObjRef:30>, 'X2': <PDFObjRef:32>, 'X3': <PDFObjRef:34>, 'X4': <PDFObjRef:36>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:99>, 'F2': <PDFObjRef:104>}}, streams=[<PDFStream(38): raw=1371, {'Filter': /'FlateDecode', 'Length': 1370}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:24.080 INFO    pdfminer.pdfinterp: get_font: create: objid=99, spec={'Type': /'Font', 'Subtype': /'Type0', 'BaseFont': /'BrandonGrotesque-Regular', 'Encoding': /'Identity-H', 'DescendantFonts': [<PDFObjRef:100>], 'ToUnicode': <PDFObjRef:103>}\n",
      "2020-11-17 23:42:24.086 INFO    pdfminer.pdfinterp: get_font: create: objid=None, spec={'Type': /'Font', 'FontDescriptor': <PDFObjRef:101>, 'BaseFont': /'BrandonGrotesque-Regular', 'Subtype': /'CIDFontType2', 'CIDToGIDMap': /'Identity', 'CIDSystemInfo': {'Registry': b'Adobe', 'Ordering': b'Identity', 'Supplement': 0}, 'W': [0, [599, 0, 0, 222], 9, [666], 36, [663, 625, 707, 747, 592, 569, 732, 764, 282, 0, 0, 491, 862, 774, 821, 596, 822, 661, 533, 478, 716, 664, 902, 0, 565, 534]], 'DW': 0, 'Encoding': /'Identity-H', 'ToUnicode': <PDFStream(103): raw=267, {'Filter': /'FlateDecode', 'Length': 266}>}\n",
      "2020-11-17 23:42:24.093 INFO    pdfminer.pdfinterp: get_font: create: objid=104, spec={'Type': /'Font', 'Subtype': /'Type0', 'BaseFont': /'BrandonGrotesque-Bold', 'Encoding': /'Identity-H', 'DescendantFonts': [<PDFObjRef:105>], 'ToUnicode': <PDFObjRef:108>}\n",
      "2020-11-17 23:42:24.097 INFO    pdfminer.pdfinterp: get_font: create: objid=None, spec={'Type': /'Font', 'FontDescriptor': <PDFObjRef:106>, 'BaseFont': /'BrandonGrotesque-Bold', 'Subtype': /'CIDFontType2', 'CIDToGIDMap': /'Identity', 'CIDSystemInfo': {'Registry': b'Adobe', 'Ordering': b'Identity', 'Supplement': 0}, 'W': [0, [599], 36, [663, 617, 0, 0, 0, 564], 47, [505, 0, 0, 800], 55, [501, 0, 0, 899]], 'DW': 0, 'Encoding': /'Identity-H', 'ToUnicode': <PDFStream(108): raw=265, {'Filter': /'FlateDecode', 'Length': 264}>}\n",
      "2020-11-17 23:42:24.128 INFO    pdfminer.pdfinterp: Processing xobj: <PDFStream(28): raw=191, {'Type': /'XObject', 'Subtype': /'Image', 'Width': 113, 'Height': 30, 'ColorSpace': /'DeviceRGB', 'SMask': <PDFObjRef:29>, 'BitsPerComponent': 8, 'Filter': /'FlateDecode', 'Length': 190}>\n",
      "2020-11-17 23:42:24.164 INFO    pdfminer.pdfinterp: Processing xobj: <PDFStream(30): raw=23, {'Type': /'XObject', 'Subtype': /'Image', 'Width': 24, 'Height': 24, 'ColorSpace': /'DeviceRGB', 'SMask': <PDFObjRef:31>, 'BitsPerComponent': 8, 'Filter': /'FlateDecode', 'Length': 22}>\n",
      "2020-11-17 23:42:24.168 INFO    pdfminer.pdfinterp: Processing xobj: <PDFStream(32): raw=23, {'Type': /'XObject', 'Subtype': /'Image', 'Width': 24, 'Height': 24, 'ColorSpace': /'DeviceRGB', 'SMask': <PDFObjRef:33>, 'BitsPerComponent': 8, 'Filter': /'FlateDecode', 'Length': 22}>\n",
      "2020-11-17 23:42:24.171 INFO    pdfminer.pdfinterp: Processing xobj: <PDFStream(34): raw=47, {'Type': /'XObject', 'Subtype': /'Image', 'Width': 25, 'Height': 24, 'ColorSpace': /'DeviceRGB', 'SMask': <PDFObjRef:35>, 'BitsPerComponent': 8, 'Filter': /'FlateDecode', 'Length': 46}>\n",
      "2020-11-17 23:42:24.174 INFO    pdfminer.pdfinterp: Processing xobj: <PDFStream(36): raw=23, {'Type': /'XObject', 'Subtype': /'Image', 'Width': 24, 'Height': 24, 'ColorSpace': /'DeviceRGB', 'SMask': <PDFObjRef:37>, 'BitsPerComponent': 8, 'Filter': /'FlateDecode', 'Length': 22}>\n",
      "2020-11-17 23:42:24.190 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:99>}}, 'MediaBox': [0, 0, 611, 791], 'Annots': [{'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [229.75, 713.25, 277, 729], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/partners.html'}}, {'Type': /'Annot', 'Subtype': /'Link', 'F': 4, 'Border': [0, 0, 0], 'Rect': [339.25, 687, 399.25, 729], 'A': {'Type': /'Action', 'S': /'URI', 'URI': b'http://www.abbott.com/online-terms-and-conditions.html'}}], 'Contents': <PDFObjRef:39>, 'Parent': <PDFObjRef:93>}\n",
      "2020-11-17 23:42:24.192 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:99>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:24.193 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'Font': {'F0': <PDFObjRef:48>, 'F1': <PDFObjRef:58>, 'F2': <PDFObjRef:99>}}, streams=[<PDFStream(39): raw=1698, {'Filter': /'FlateDecode', 'Length': 1697}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:24.285 INFO    pdfminer.pdfpage: Page: {'Type': /'Page', 'Resources': {'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'XObject': {'X0': <PDFObjRef:40>}, 'Font': {'F0': <PDFObjRef:48>}}, 'MediaBox': [0, 0, 611, 791], 'Contents': <PDFObjRef:42>, 'Parent': <PDFObjRef:93>}\n",
      "2020-11-17 23:42:24.287 INFO    pdfminer.pdfinterp: Processing page: <PDFPage: Resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'XObject': {'X0': <PDFObjRef:40>}, 'Font': {'F0': <PDFObjRef:48>}}, MediaBox=[0, 0, 611, 791]>\n",
      "2020-11-17 23:42:24.289 INFO    pdfminer.pdfinterp: render_contents: resources={'ProcSets': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G0': <PDFObjRef:47>}, 'XObject': {'X0': <PDFObjRef:40>}, 'Font': {'F0': <PDFObjRef:48>}}, streams=[<PDFStream(42): raw=367, {'Filter': /'FlateDecode', 'Length': 366}>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "2020-11-17 23:42:24.300 INFO    pdfminer.pdfinterp: Processing xobj: <PDFStream(40): raw=12, {'Type': /'XObject', 'Subtype': /'Image', 'Width': 1, 'Height': 1, 'ColorSpace': /'DeviceRGB', 'SMask': <PDFObjRef:41>, 'BitsPerComponent': 8, 'Filter': /'FlateDecode', 'Length': 11}>\n",
      "100%|██████████| 50/50 [02:17<00:00,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"data//Indusonlyfiles = [f for f in os.listdir(DIR_REPORTS) if os.path.isfile(os.path.join(DIR_REPORTS, f))]pdf = d.DataFrame()onlyfiles, columns=[\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = preprocess.load_processed_text(\n",
    "    df,\n",
    "    dir_read_pdf=DIR_REPORTS, \n",
    "    columns_to_keep = [\"filename\"],\n",
    "    file_processed_text=\"output/Cgovernance_processed_pdfMiner.txt\",\n",
    "    n_min_word_paragraph=50, \n",
    "    n_max_word_paragraph=125,  \n",
    "    update=True,\n",
    "    method_extract_content = \"pdfMiner\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:42:26.465 INFO    numexpr.utils: NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "# save only the paragraph to a text file\n",
    "df_processed[\"paragraph\"].to_csv('output/Cgovernance_processed_raw_pdfMiner.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1520, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our list contains all english stop words \n",
    "stop_words = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✔ Download and installation successful\nYou can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# load spacy model to lematize text\n",
    "nlp = preprocess.load_spacy_model()"
   ]
  },
  {
   "source": [
    "## 1. Contextualized Topic Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.1 Prepare data for model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1520/1520 [00:47<00:00, 31.76it/s]\n"
     ]
    }
   ],
   "source": [
    "df_processed = preprocess.load_lemmatize(\n",
    "    data=df_processed, \n",
    "    dir_file='output/Cgovernance_processed_cleaned_pdfMiner.txt', \n",
    "    stop_words=stop_words, \n",
    "    nlp=nlp, \n",
    "    method=1, \n",
    "    update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1520, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            filename  \\\n",
       "0  20171024_HBI_Corporate_Governance_Report_SD000...   \n",
       "1  20171024_HBI_Corporate_Governance_Report_SD000...   \n",
       "2  20171024_HBI_Corporate_Governance_Report_SD000...   \n",
       "3  20171024_HBI_Corporate_Governance_Report_SD000...   \n",
       "4  20171024_HBI_Corporate_Governance_Report_SD000...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  HANESBRANDS INC CORPORATE GOVERNANCE GUIDELINE...   \n",
       "1  candidate has served in policy making roles in...   \n",
       "2  Board shall approve the nomination or the elec...   \n",
       "3  virtue of any applicable law or authority The ...   \n",
       "4  knowledge of Hanesbrands business In addition ...   \n",
       "\n",
       "                                   paragraph_cleaned  \n",
       "0  hanesbrands corporate governance guideline dir...  \n",
       "1  candidate serve policy making role business go...  \n",
       "2  board shall approve nomination election direct...  \n",
       "3  virtue applicable authority board shall elect ...  \n",
       "4  knowledge hanesbrand business addition board r...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>paragraph</th>\n      <th>paragraph_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20171024_HBI_Corporate_Governance_Report_SD000...</td>\n      <td>HANESBRANDS INC CORPORATE GOVERNANCE GUIDELINE...</td>\n      <td>hanesbrands corporate governance guideline dir...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20171024_HBI_Corporate_Governance_Report_SD000...</td>\n      <td>candidate has served in policy making roles in...</td>\n      <td>candidate serve policy making role business go...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20171024_HBI_Corporate_Governance_Report_SD000...</td>\n      <td>Board shall approve the nomination or the elec...</td>\n      <td>board shall approve nomination election direct...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20171024_HBI_Corporate_Governance_Report_SD000...</td>\n      <td>virtue of any applicable law or authority The ...</td>\n      <td>virtue applicable authority board shall elect ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20171024_HBI_Corporate_Governance_Report_SD000...</td>\n      <td>knowledge of Hanesbrands business In addition ...</td>\n      <td>knowledge hanesbrand business addition board r...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "print(df_processed.shape)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:43:23.009 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-17 23:43:23.240 INFO    gensim.corpora.dictionary: built Dictionary(2853 unique tokens: ['activity', 'applicable', 'arena', 'assessment', 'background']...) from 1520 documents (total 94899 corpus positions)\n",
      "2020-11-17 23:43:23.246 INFO    gensim.corpora.dictionary: discarding 1639 tokens: [('applicable', 255), ('arena', 2), ('board', 1360), ('business', 378), ('committee', 1043), ('company', 807), ('consider', 299), ('corporate', 550), ('director', 1304), ('distinguish', 1)]...\n",
      "2020-11-17 23:43:23.247 INFO    gensim.corpora.dictionary: keeping 1214 tokens which were in no less than 5 and no more than 228 (=15.0%) documents\n",
      "2020-11-17 23:43:23.255 INFO    gensim.corpora.dictionary: resulting dictionary: Dictionary(1214 unique tokens: ['activity', 'assessment', 'background', 'candidate', 'competence']...)\n",
      "1214\n"
     ]
    }
   ],
   "source": [
    "with open('output/Cgovernance_processed_cleaned_pdfMiner.txt',\"r\") as fr:\n",
    "    text_cleaned = [doc.split() for doc in fr.read().splitlines()] # load text for NPMI\n",
    "\n",
    "dictionary = Dictionary(text_cleaned)\n",
    "\n",
    "'''\n",
    "Remove very rare and very common words:\n",
    "\n",
    "- words appearing less than 5 times\n",
    "- words appearing in more than 15% of all documents\n",
    "'''\n",
    "\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.15, keep_n= 100000)\n",
    "print(len(dictionary.token2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in text_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1520, 1214)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tf_array = matutils.corpus2dense(bow_corpus, num_terms=len(dictionary.token2id)).T\n",
    "tf_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<1520x1214 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 41522 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# convert to sparse matrix\n",
    "tf_array_sparse = sparse.csr_matrix(tf_array)\n",
    "tf_array_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:43:23.634 INFO    root: Load pretrained SentenceTransformer: distiluse-base-multilingual-cased\n",
      "2020-11-17 23:43:23.636 INFO    root: Did not find folder distiluse-base-multilingual-cased. Assume to download model from server.\n",
      "2020-11-17 23:43:23.641 INFO    root: Load SentenceTransformer from folder: C:\\Users\\Pieter-Jan/.cache\\torch\\sentence_transformers\\sbert.net_models_distiluse-base-multilingual-cased\n",
      "2020-11-17 23:43:27.138 INFO    root: Use pytorch device: cpu\n",
      "Batches: 100%|██████████| 8/8 [04:42<00:00, 35.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# create or load bert embeddings (either use raw text or clean text)\n",
    "# we can expirment with both\n",
    "embeddings_bert = preprocess.load_bert_embeddings(\n",
    "        text_dir=\"output/Cgovernance_processed_raw_pdfMiner.txt\", \n",
    "        model=\"distiluse-base-multilingual-cased\",\n",
    "        dir_embeddings=\"output/Cgovernance_bertEmbeddings_pdfMiner.npy\",\n",
    "        update=True\n",
    ")"
   ]
  },
  {
   "source": [
    "## 1.2 Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1520, 512)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "embeddings_bert.shape"
   ]
  },
  {
   "source": [
    "## 1.3 Evaluate topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ivert dictionary\n",
    "inv_token2id = {v: k for k, v in dictionary.token2id.items()}\n",
    "# create dataset\n",
    "training_dataset = CTMDataset(tf_array_sparse, embeddings_bert, inv_token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Settings: \n",
      "                   N Components: 8\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.875\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: True\n",
      "                   Save Dir: None\n",
      "Epoch: [1/20]\tSamples: [1520/30400]\tTrain Loss: 261.2963443153783\tTime: 0:00:08.091877\n",
      "Epoch: [2/20]\tSamples: [3040/30400]\tTrain Loss: 255.32405941611842\tTime: 0:00:07.598107\n",
      "Epoch: [3/20]\tSamples: [4560/30400]\tTrain Loss: 251.37415771484376\tTime: 0:00:10.079666\n",
      "Epoch: [4/20]\tSamples: [6080/30400]\tTrain Loss: 247.277976588199\tTime: 0:00:09.409812\n",
      "Epoch: [5/20]\tSamples: [7600/30400]\tTrain Loss: 244.75961014597038\tTime: 0:00:08.388969\n",
      "Epoch: [6/20]\tSamples: [9120/30400]\tTrain Loss: 242.36711168791118\tTime: 0:00:07.036029\n",
      "Epoch: [7/20]\tSamples: [10640/30400]\tTrain Loss: 240.75178286903784\tTime: 0:00:08.029855\n",
      "Epoch: [8/20]\tSamples: [12160/30400]\tTrain Loss: 239.26569310238486\tTime: 0:00:07.224613\n",
      "Epoch: [9/20]\tSamples: [13680/30400]\tTrain Loss: 237.62603502775494\tTime: 0:00:07.760923\n",
      "Epoch: [10/20]\tSamples: [15200/30400]\tTrain Loss: 236.8647640830592\tTime: 0:00:07.143753\n",
      "Epoch: [11/20]\tSamples: [16720/30400]\tTrain Loss: 235.9530318410773\tTime: 0:00:07.772445\n",
      "Epoch: [12/20]\tSamples: [18240/30400]\tTrain Loss: 235.35395893297698\tTime: 0:00:07.355931\n",
      "Epoch: [13/20]\tSamples: [19760/30400]\tTrain Loss: 234.43618742290295\tTime: 0:00:08.088071\n",
      "Epoch: [14/20]\tSamples: [21280/30400]\tTrain Loss: 234.73258956106085\tTime: 0:00:07.752837\n",
      "Epoch: [15/20]\tSamples: [22800/30400]\tTrain Loss: 234.120408228824\tTime: 0:00:08.172135\n",
      "Epoch: [16/20]\tSamples: [24320/30400]\tTrain Loss: 232.94173776726973\tTime: 0:00:07.185394\n",
      "Epoch: [17/20]\tSamples: [25840/30400]\tTrain Loss: 232.88771394428454\tTime: 0:00:07.676428\n",
      "Epoch: [18/20]\tSamples: [27360/30400]\tTrain Loss: 232.308982447574\tTime: 0:00:09.002072\n",
      "Epoch: [19/20]\tSamples: [28880/30400]\tTrain Loss: 232.16301526521383\tTime: 0:00:08.953190\n",
      "Epoch: [20/20]\tSamples: [30400/30400]\tTrain Loss: 232.15686163651316\tTime: 0:00:08.432384\n"
     ]
    }
   ],
   "source": [
    "random.seed(69)\n",
    "ctm = CTM(\n",
    "    input_size=len(dictionary.token2id), \n",
    "    bert_input_size=512, \n",
    "    n_components=8, \n",
    "    inference_type=\"combined\",\n",
    "    num_epochs=20,\n",
    "    reduce_on_plateau=True\n",
    "    )\n",
    "ctm.fit(training_dataset) # run model"
   ]
  },
  {
   "source": [
    "### 1.3.1 Normalized Point-wise Mutual Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt_topics_l = ctm.get_topic_lists(10)\n",
    "cmt_topics_d = {}\n",
    "for i in range(len(cmt_topics_l)):\n",
    "    cmt_topics_d[i] = cmt_topics_l[i]"
   ]
  },
  {
   "source": [
    "### 1.3.2 External Word Embeddings Topic Coherence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             0             1          2           3          4           5  \\\n",
       "0  resignation          vote   election     nominee     tender      accept   \n",
       "1     annually  periodically    charter   guideline  education     program   \n",
       "2   experience         skill  criterion  background    nominee  retirement   \n",
       "3      advisor         party       code     general     matter      access   \n",
       "4        stock   requirement   standard        york       cash   ownership   \n",
       "5      oversee       process       risk      report   function  evaluation   \n",
       "6       agenda          item    advance  distribute    session      attend   \n",
       "7       family   consolidate    revenue       gross  immediate     payment   \n",
       "\n",
       "              6              7              8           9  \n",
       "0         offer  certification       majority    promptly  \n",
       "1   orientation           base       continue        duty  \n",
       "2         limit      candidate      diversity      commit  \n",
       "3         legal   confidential  communication       ethic  \n",
       "4      exchange         market           list      common  \n",
       "5     financial       evaluate        approve    strategy  \n",
       "6      schedule       material     discussion  attendance  \n",
       "7  relationship         fiscal   organization     partner  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resignation</td>\n      <td>vote</td>\n      <td>election</td>\n      <td>nominee</td>\n      <td>tender</td>\n      <td>accept</td>\n      <td>offer</td>\n      <td>certification</td>\n      <td>majority</td>\n      <td>promptly</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>annually</td>\n      <td>periodically</td>\n      <td>charter</td>\n      <td>guideline</td>\n      <td>education</td>\n      <td>program</td>\n      <td>orientation</td>\n      <td>base</td>\n      <td>continue</td>\n      <td>duty</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>experience</td>\n      <td>skill</td>\n      <td>criterion</td>\n      <td>background</td>\n      <td>nominee</td>\n      <td>retirement</td>\n      <td>limit</td>\n      <td>candidate</td>\n      <td>diversity</td>\n      <td>commit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>advisor</td>\n      <td>party</td>\n      <td>code</td>\n      <td>general</td>\n      <td>matter</td>\n      <td>access</td>\n      <td>legal</td>\n      <td>confidential</td>\n      <td>communication</td>\n      <td>ethic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>stock</td>\n      <td>requirement</td>\n      <td>standard</td>\n      <td>york</td>\n      <td>cash</td>\n      <td>ownership</td>\n      <td>exchange</td>\n      <td>market</td>\n      <td>list</td>\n      <td>common</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>oversee</td>\n      <td>process</td>\n      <td>risk</td>\n      <td>report</td>\n      <td>function</td>\n      <td>evaluation</td>\n      <td>financial</td>\n      <td>evaluate</td>\n      <td>approve</td>\n      <td>strategy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>agenda</td>\n      <td>item</td>\n      <td>advance</td>\n      <td>distribute</td>\n      <td>session</td>\n      <td>attend</td>\n      <td>schedule</td>\n      <td>material</td>\n      <td>discussion</td>\n      <td>attendance</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>family</td>\n      <td>consolidate</td>\n      <td>revenue</td>\n      <td>gross</td>\n      <td>immediate</td>\n      <td>payment</td>\n      <td>relationship</td>\n      <td>fiscal</td>\n      <td>organization</td>\n      <td>partner</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(cmt_topics_d).T"
   ]
  },
  {
   "source": [
    "### 1.3.3 Rank-Biased Overlap "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:50:51.297 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-17 23:50:51.569 INFO    gensim.corpora.dictionary: built Dictionary(2853 unique tokens: ['activity', 'applicable', 'arena', 'assessment', 'background']...) from 1520 documents (total 94899 corpus positions)\n",
      "2020-11-17 23:50:51.577 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-11-17 23:50:57.712 INFO    gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (3501 virtual)\n",
      "2020-11-17 23:50:57.719 INFO    gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (7082 virtual)\n",
      "2020-11-17 23:50:57.725 INFO    gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (10724 virtual)\n",
      "2020-11-17 23:50:57.732 INFO    gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (13971 virtual)\n",
      "2020-11-17 23:50:57.738 INFO    gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (17536 virtual)\n",
      "2020-11-17 23:50:57.743 INFO    gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (21188 virtual)\n",
      "2020-11-17 23:50:57.888 INFO    gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (24795 virtual)\n",
      "2020-11-17 23:50:57.904 INFO    gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (28343 virtual)\n",
      "2020-11-17 23:50:57.940 INFO    gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (31282 virtual)\n",
      "2020-11-17 23:50:58.003 INFO    gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (34912 virtual)\n",
      "2020-11-17 23:50:58.048 INFO    gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (38695 virtual)\n",
      "2020-11-17 23:50:58.058 INFO    gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (42322 virtual)\n",
      "2020-11-17 23:50:58.137 INFO    gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (46238 virtual)\n",
      "2020-11-17 23:50:58.176 INFO    gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (49771 virtual)\n",
      "2020-11-17 23:50:58.181 INFO    gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (53340 virtual)\n",
      "2020-11-17 23:50:58.265 INFO    gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (56750 virtual)\n",
      "2020-11-17 23:50:58.300 INFO    gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (60002 virtual)\n",
      "2020-11-17 23:50:58.306 INFO    gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (63634 virtual)\n",
      "2020-11-17 23:50:58.402 INFO    gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (67192 virtual)\n",
      "2020-11-17 23:50:58.423 INFO    gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (70382 virtual)\n",
      "2020-11-17 23:50:58.436 INFO    gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (74006 virtual)\n",
      "2020-11-17 23:50:58.522 INFO    gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (77077 virtual)\n",
      "2020-11-17 23:50:58.543 INFO    gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (79898 virtual)\n",
      "2020-11-17 23:50:58.553 INFO    gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (80865 virtual)\n",
      "2020-11-17 23:50:58.883 INFO    gensim.topic_coherence.text_analysis: 3 accumulators retrieved from output queue\n",
      "2020-11-17 23:50:58.920 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 80877 virtual documents\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.10366851974616874"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "npmi = CoherenceNPMI(texts=text_cleaned, topics=ctm.get_topic_lists(10))\n",
    "npmi.score()"
   ]
  },
  {
   "source": [
    "## 2. Latent Dirichlet Allocation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1 Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:50:59.360 INFO    gensim.models.utils_any2vec: loading projection weights from C:\\Users\\Pieter-Jan/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2020-11-17 23:52:21.873 INFO    gensim.models.utils_any2vec: loaded (3000000, 300) matrix from C:\\Users\\Pieter-Jan/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.14070016"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "CoherenceWordEmbeddings(ctm.get_topic_lists(10)).score()"
   ]
  },
  {
   "source": [
    "## 2.2 Evaluate topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9971407413058674"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "InvertedRBO(ctm.get_topic_lists(10)).score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:52:23.214 INFO    gensim.models.ldamodel: using symmetric alpha at 0.125\n",
      "2020-11-17 23:52:23.217 INFO    gensim.models.ldamodel: using symmetric eta at 0.125\n",
      "2020-11-17 23:52:23.219 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2020-11-17 23:52:23.225 INFO    gensim.models.ldamulticore: running online LDA training, 8 topics, 10 passes over the supplied corpus of 1520 documents, updating every 4000 documents, evaluating every ~1520 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-11-17 23:52:23.232 INFO    gensim.models.ldamulticore: training LDA model using 2 processes\n",
      "2020-11-17 23:52:23.335 INFO    gensim.models.ldamulticore: PROGRESS: pass 0, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:27.354 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.023*\"evaluation\" + 0.015*\"agenda\" + 0.013*\"session\" + 0.012*\"succession\" + 0.009*\"stock\" + 0.008*\"audit\" + 0.008*\"report\" + 0.007*\"plan\" + 0.007*\"annually\" + 0.007*\"self\"\n",
      "2020-11-17 23:52:27.356 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.011*\"plan\" + 0.009*\"shareholder\" + 0.009*\"guideline\" + 0.008*\"evaluation\" + 0.008*\"advisor\" + 0.007*\"conduct\" + 0.007*\"financial\" + 0.007*\"individual\" + 0.007*\"stockholder\" + 0.007*\"relationship\"\n",
      "2020-11-17 23:52:27.360 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.014*\"guideline\" + 0.012*\"stock\" + 0.008*\"ownership\" + 0.008*\"audit\" + 0.008*\"evaluation\" + 0.008*\"expect\" + 0.008*\"stockholder\" + 0.007*\"standard\" + 0.007*\"charter\" + 0.006*\"shareholder\"\n",
      "2020-11-17 23:52:27.363 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.013*\"guideline\" + 0.011*\"agenda\" + 0.011*\"information\" + 0.011*\"corporation\" + 0.007*\"necessary\" + 0.007*\"transaction\" + 0.007*\"believe\" + 0.006*\"require\" + 0.006*\"deem\" + 0.006*\"compliance\"\n",
      "2020-11-17 23:52:27.366 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.014*\"change\" + 0.012*\"candidate\" + 0.012*\"stockholder\" + 0.011*\"plan\" + 0.011*\"recommend\" + 0.010*\"resignation\" + 0.009*\"succession\" + 0.008*\"circumstance\" + 0.008*\"audit\" + 0.008*\"accept\"\n",
      "2020-11-17 23:52:27.367 INFO    gensim.models.ldamodel: topic diff=2.067747, rho=1.000000\n",
      "2020-11-17 23:52:29.920 INFO    gensim.models.ldamodel: -6.712 per-word bound, 104.9 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:29.923 INFO    gensim.models.ldamulticore: PROGRESS: pass 1, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:31.379 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.015*\"continue\" + 0.014*\"program\" + 0.013*\"education\" + 0.013*\"orientation\" + 0.010*\"limit\" + 0.010*\"advisor\" + 0.009*\"relationship\" + 0.009*\"expect\" + 0.008*\"attend\" + 0.008*\"material\"\n",
      "2020-11-17 23:52:31.381 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.019*\"stock\" + 0.018*\"guideline\" + 0.012*\"ownership\" + 0.008*\"audit\" + 0.008*\"require\" + 0.007*\"expect\" + 0.007*\"share\" + 0.007*\"standard\" + 0.007*\"stockholder\" + 0.007*\"shareholder\"\n",
      "2020-11-17 23:52:31.382 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.028*\"evaluation\" + 0.018*\"session\" + 0.017*\"agenda\" + 0.016*\"succession\" + 0.011*\"development\" + 0.010*\"report\" + 0.010*\"senior\" + 0.009*\"plan\" + 0.009*\"annually\" + 0.009*\"audit\"\n",
      "2020-11-17 23:52:31.384 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.028*\"resignation\" + 0.024*\"election\" + 0.022*\"vote\" + 0.013*\"receive\" + 0.011*\"majority\" + 0.010*\"family\" + 0.010*\"accept\" + 0.010*\"offer\" + 0.009*\"exchange\" + 0.009*\"number\"\n",
      "2020-11-17 23:52:31.387 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.013*\"plan\" + 0.011*\"shareholder\" + 0.010*\"advisor\" + 0.008*\"financial\" + 0.008*\"guideline\" + 0.008*\"family\" + 0.007*\"immediate\" + 0.007*\"necessary\" + 0.007*\"conduct\" + 0.006*\"stockholder\"\n",
      "2020-11-17 23:52:31.391 INFO    gensim.models.ldamodel: topic diff=0.495090, rho=0.601929\n",
      "2020-11-17 23:52:33.684 INFO    gensim.models.ldamodel: -6.592 per-word bound, 96.5 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:33.687 INFO    gensim.models.ldamulticore: PROGRESS: pass 2, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:34.913 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.031*\"evaluation\" + 0.020*\"session\" + 0.019*\"succession\" + 0.016*\"agenda\" + 0.013*\"development\" + 0.012*\"senior\" + 0.011*\"plan\" + 0.011*\"report\" + 0.010*\"annually\" + 0.010*\"charter\"\n",
      "2020-11-17 23:52:34.914 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.032*\"resignation\" + 0.027*\"election\" + 0.023*\"vote\" + 0.013*\"receive\" + 0.013*\"majority\" + 0.011*\"family\" + 0.011*\"accept\" + 0.010*\"offer\" + 0.010*\"immediate\" + 0.010*\"exchange\"\n",
      "2020-11-17 23:52:34.915 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.018*\"continue\" + 0.018*\"program\" + 0.018*\"orientation\" + 0.017*\"education\" + 0.011*\"limit\" + 0.010*\"advisor\" + 0.010*\"relationship\" + 0.009*\"material\" + 0.009*\"attend\" + 0.009*\"expect\"\n",
      "2020-11-17 23:52:34.920 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.016*\"corporation\" + 0.014*\"information\" + 0.014*\"guideline\" + 0.013*\"transaction\" + 0.009*\"believe\" + 0.008*\"party\" + 0.008*\"person\" + 0.008*\"organization\" + 0.007*\"relationship\" + 0.007*\"agenda\"\n",
      "2020-11-17 23:52:34.923 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.021*\"candidate\" + 0.018*\"change\" + 0.014*\"recommend\" + 0.012*\"stockholder\" + 0.010*\"circumstance\" + 0.010*\"membership\" + 0.010*\"public\" + 0.009*\"plan\" + 0.009*\"position\" + 0.008*\"nomination\"\n",
      "2020-11-17 23:52:34.925 INFO    gensim.models.ldamodel: topic diff=0.436957, rho=0.515711\n",
      "2020-11-17 23:52:36.727 INFO    gensim.models.ldamodel: -6.515 per-word bound, 91.4 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:36.729 INFO    gensim.models.ldamulticore: PROGRESS: pass 3, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:38.374 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.021*\"program\" + 0.021*\"orientation\" + 0.021*\"continue\" + 0.020*\"education\" + 0.012*\"limit\" + 0.011*\"advisor\" + 0.010*\"relationship\" + 0.009*\"material\" + 0.009*\"attend\" + 0.009*\"financial\"\n",
      "2020-11-17 23:52:38.375 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.033*\"evaluation\" + 0.022*\"succession\" + 0.020*\"session\" + 0.015*\"development\" + 0.014*\"agenda\" + 0.014*\"senior\" + 0.013*\"plan\" + 0.012*\"report\" + 0.012*\"annually\" + 0.011*\"charter\"\n",
      "2020-11-17 23:52:38.377 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.018*\"corporation\" + 0.016*\"transaction\" + 0.015*\"information\" + 0.014*\"guideline\" + 0.010*\"party\" + 0.009*\"person\" + 0.009*\"believe\" + 0.009*\"organization\" + 0.008*\"discover\" + 0.008*\"relationship\"\n",
      "2020-11-17 23:52:38.379 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.014*\"advisor\" + 0.013*\"plan\" + 0.012*\"shareholder\" + 0.010*\"financial\" + 0.010*\"family\" + 0.009*\"immediate\" + 0.009*\"legal\" + 0.009*\"receive\" + 0.008*\"fee\" + 0.008*\"deem\"\n",
      "2020-11-17 23:52:38.383 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.028*\"stock\" + 0.023*\"guideline\" + 0.015*\"ownership\" + 0.012*\"share\" + 0.009*\"require\" + 0.008*\"requirement\" + 0.008*\"standard\" + 0.008*\"fifth\" + 0.007*\"value\" + 0.007*\"shareholder\"\n",
      "2020-11-17 23:52:38.386 INFO    gensim.models.ldamodel: topic diff=0.382403, rho=0.458349\n",
      "2020-11-17 23:52:39.811 INFO    gensim.models.ldamodel: -6.466 per-word bound, 88.4 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:39.814 INFO    gensim.models.ldamulticore: PROGRESS: pass 4, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:40.936 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.031*\"stock\" + 0.026*\"guideline\" + 0.016*\"ownership\" + 0.014*\"share\" + 0.009*\"require\" + 0.009*\"requirement\" + 0.009*\"fifth\" + 0.008*\"value\" + 0.008*\"standard\" + 0.007*\"conduct\"\n",
      "2020-11-17 23:52:40.937 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.016*\"advisor\" + 0.014*\"plan\" + 0.012*\"shareholder\" + 0.011*\"family\" + 0.011*\"financial\" + 0.010*\"immediate\" + 0.009*\"legal\" + 0.009*\"receive\" + 0.009*\"fee\" + 0.008*\"deem\"\n",
      "2020-11-17 23:52:40.938 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.035*\"evaluation\" + 0.024*\"succession\" + 0.020*\"session\" + 0.016*\"development\" + 0.015*\"senior\" + 0.015*\"plan\" + 0.013*\"report\" + 0.013*\"annually\" + 0.012*\"agenda\" + 0.012*\"charter\"\n",
      "2020-11-17 23:52:40.941 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.035*\"resignation\" + 0.028*\"election\" + 0.025*\"vote\" + 0.014*\"majority\" + 0.014*\"receive\" + 0.013*\"family\" + 0.012*\"accept\" + 0.012*\"independence\" + 0.011*\"exchange\" + 0.011*\"immediate\"\n",
      "2020-11-17 23:52:40.944 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.024*\"program\" + 0.024*\"orientation\" + 0.022*\"continue\" + 0.022*\"education\" + 0.012*\"limit\" + 0.011*\"advisor\" + 0.010*\"relationship\" + 0.010*\"material\" + 0.010*\"financial\" + 0.009*\"operation\"\n",
      "2020-11-17 23:52:40.949 INFO    gensim.models.ldamodel: topic diff=0.335869, rho=0.416667\n",
      "2020-11-17 23:52:43.331 INFO    gensim.models.ldamodel: -6.431 per-word bound, 86.3 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:43.333 INFO    gensim.models.ldamulticore: PROGRESS: pass 5, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:44.399 INFO    gensim.models.ldamodel: topic #7 (0.125): 0.040*\"agenda\" + 0.019*\"material\" + 0.017*\"advance\" + 0.015*\"item\" + 0.014*\"stockholder\" + 0.014*\"schedule\" + 0.014*\"information\" + 0.013*\"expect\" + 0.013*\"communication\" + 0.012*\"session\"\n",
      "2020-11-17 23:52:44.401 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.025*\"candidate\" + 0.020*\"change\" + 0.015*\"recommend\" + 0.014*\"experience\" + 0.013*\"public\" + 0.013*\"membership\" + 0.011*\"nominee\" + 0.010*\"circumstance\" + 0.010*\"stockholder\" + 0.010*\"criterion\"\n",
      "2020-11-17 23:52:44.402 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.021*\"corporation\" + 0.019*\"transaction\" + 0.017*\"information\" + 0.014*\"guideline\" + 0.012*\"person\" + 0.011*\"party\" + 0.011*\"discover\" + 0.010*\"organization\" + 0.010*\"believe\" + 0.009*\"related\"\n",
      "2020-11-17 23:52:44.403 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.036*\"resignation\" + 0.029*\"election\" + 0.026*\"vote\" + 0.015*\"majority\" + 0.014*\"receive\" + 0.013*\"family\" + 0.013*\"independence\" + 0.013*\"accept\" + 0.012*\"exchange\" + 0.012*\"relationship\"\n",
      "2020-11-17 23:52:44.407 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.026*\"program\" + 0.025*\"orientation\" + 0.024*\"education\" + 0.023*\"continue\" + 0.012*\"limit\" + 0.011*\"advisor\" + 0.010*\"financial\" + 0.010*\"accounting\" + 0.010*\"relationship\" + 0.010*\"material\"\n",
      "2020-11-17 23:52:44.414 INFO    gensim.models.ldamodel: topic diff=0.294179, rho=0.384615\n",
      "2020-11-17 23:52:46.432 INFO    gensim.models.ldamodel: -6.406 per-word bound, 84.8 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:46.433 INFO    gensim.models.ldamulticore: PROGRESS: pass 6, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:47.726 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.026*\"candidate\" + 0.020*\"change\" + 0.015*\"experience\" + 0.015*\"recommend\" + 0.013*\"public\" + 0.013*\"membership\" + 0.011*\"nominee\" + 0.010*\"circumstance\" + 0.010*\"criterion\" + 0.010*\"election\"\n",
      "2020-11-17 23:52:47.728 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.037*\"evaluation\" + 0.026*\"succession\" + 0.020*\"session\" + 0.018*\"development\" + 0.017*\"plan\" + 0.017*\"senior\" + 0.014*\"annually\" + 0.014*\"charter\" + 0.014*\"report\" + 0.012*\"planning\"\n",
      "2020-11-17 23:52:47.730 INFO    gensim.models.ldamodel: topic #7 (0.125): 0.041*\"agenda\" + 0.020*\"material\" + 0.017*\"advance\" + 0.015*\"item\" + 0.015*\"stockholder\" + 0.015*\"schedule\" + 0.014*\"communication\" + 0.014*\"information\" + 0.014*\"expect\" + 0.013*\"session\"\n",
      "2020-11-17 23:52:47.732 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.035*\"stock\" + 0.029*\"guideline\" + 0.018*\"ownership\" + 0.015*\"share\" + 0.010*\"fifth\" + 0.010*\"requirement\" + 0.009*\"require\" + 0.009*\"value\" + 0.009*\"conduct\" + 0.008*\"code\"\n",
      "2020-11-17 23:52:47.736 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.018*\"advisor\" + 0.014*\"plan\" + 0.013*\"shareholder\" + 0.012*\"family\" + 0.011*\"financial\" + 0.011*\"immediate\" + 0.010*\"receive\" + 0.010*\"fee\" + 0.010*\"legal\" + 0.009*\"deem\"\n",
      "2020-11-17 23:52:47.738 INFO    gensim.models.ldamodel: topic diff=0.258156, rho=0.358979\n",
      "2020-11-17 23:52:49.485 INFO    gensim.models.ldamodel: -6.388 per-word bound, 83.7 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:49.489 INFO    gensim.models.ldamulticore: PROGRESS: pass 7, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:50.510 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.037*\"resignation\" + 0.029*\"election\" + 0.027*\"vote\" + 0.015*\"majority\" + 0.014*\"independence\" + 0.014*\"receive\" + 0.014*\"family\" + 0.014*\"relationship\" + 0.013*\"accept\" + 0.013*\"exchange\"\n",
      "2020-11-17 23:52:50.512 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.038*\"evaluation\" + 0.027*\"succession\" + 0.019*\"session\" + 0.018*\"development\" + 0.018*\"plan\" + 0.017*\"senior\" + 0.015*\"annually\" + 0.014*\"charter\" + 0.014*\"report\" + 0.012*\"planning\"\n",
      "2020-11-17 23:52:50.513 INFO    gensim.models.ldamodel: topic #7 (0.125): 0.042*\"agenda\" + 0.020*\"material\" + 0.017*\"advance\" + 0.016*\"item\" + 0.015*\"schedule\" + 0.015*\"stockholder\" + 0.015*\"communication\" + 0.014*\"expect\" + 0.014*\"information\" + 0.014*\"session\"\n",
      "2020-11-17 23:52:50.514 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.026*\"candidate\" + 0.021*\"change\" + 0.016*\"experience\" + 0.015*\"recommend\" + 0.014*\"public\" + 0.013*\"membership\" + 0.011*\"nominee\" + 0.010*\"criterion\" + 0.010*\"election\" + 0.010*\"nomination\"\n",
      "2020-11-17 23:52:50.517 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.036*\"stock\" + 0.031*\"guideline\" + 0.018*\"ownership\" + 0.016*\"share\" + 0.011*\"fifth\" + 0.010*\"requirement\" + 0.009*\"require\" + 0.009*\"value\" + 0.009*\"conduct\" + 0.008*\"code\"\n",
      "2020-11-17 23:52:50.521 INFO    gensim.models.ldamodel: topic diff=0.227113, rho=0.337869\n",
      "2020-11-17 23:52:52.213 INFO    gensim.models.ldamodel: -6.374 per-word bound, 82.9 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:52.216 INFO    gensim.models.ldamulticore: PROGRESS: pass 8, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:53.458 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.029*\"program\" + 0.029*\"orientation\" + 0.027*\"education\" + 0.025*\"continue\" + 0.012*\"financial\" + 0.012*\"advisor\" + 0.012*\"limit\" + 0.012*\"accounting\" + 0.011*\"outside\" + 0.011*\"operation\"\n",
      "2020-11-17 23:52:53.459 INFO    gensim.models.ldamodel: topic #7 (0.125): 0.043*\"agenda\" + 0.020*\"material\" + 0.017*\"advance\" + 0.016*\"item\" + 0.016*\"schedule\" + 0.015*\"stockholder\" + 0.015*\"communication\" + 0.014*\"session\" + 0.014*\"expect\" + 0.014*\"information\"\n",
      "2020-11-17 23:52:53.461 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.037*\"resignation\" + 0.029*\"election\" + 0.027*\"vote\" + 0.016*\"majority\" + 0.015*\"independence\" + 0.014*\"receive\" + 0.014*\"relationship\" + 0.014*\"family\" + 0.013*\"exchange\" + 0.013*\"accept\"\n",
      "2020-11-17 23:52:53.461 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.024*\"corporation\" + 0.022*\"transaction\" + 0.019*\"information\" + 0.015*\"person\" + 0.013*\"party\" + 0.012*\"guideline\" + 0.012*\"discover\" + 0.011*\"related\" + 0.011*\"organization\" + 0.010*\"confidential\"\n",
      "2020-11-17 23:52:53.463 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.019*\"advisor\" + 0.013*\"plan\" + 0.013*\"shareholder\" + 0.012*\"financial\" + 0.012*\"family\" + 0.012*\"receive\" + 0.012*\"immediate\" + 0.011*\"fee\" + 0.011*\"legal\" + 0.010*\"deem\"\n",
      "2020-11-17 23:52:53.466 INFO    gensim.models.ldamodel: topic diff=0.200738, rho=0.320092\n",
      "2020-11-17 23:52:55.027 INFO    gensim.models.ldamodel: -6.362 per-word bound, 82.3 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n",
      "2020-11-17 23:52:55.029 INFO    gensim.models.ldamulticore: PROGRESS: pass 9, dispatched chunk #0 = documents up to #1520/1520, outstanding queue size 1\n",
      "2020-11-17 23:52:56.157 INFO    gensim.models.ldamodel: topic #2 (0.125): 0.037*\"stock\" + 0.033*\"guideline\" + 0.019*\"ownership\" + 0.016*\"share\" + 0.012*\"fifth\" + 0.010*\"requirement\" + 0.010*\"conduct\" + 0.010*\"value\" + 0.009*\"require\" + 0.009*\"code\"\n",
      "2020-11-17 23:52:56.158 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.037*\"resignation\" + 0.029*\"election\" + 0.027*\"vote\" + 0.016*\"independence\" + 0.016*\"majority\" + 0.015*\"relationship\" + 0.014*\"receive\" + 0.014*\"family\" + 0.013*\"exchange\" + 0.013*\"accept\"\n",
      "2020-11-17 23:52:56.159 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.040*\"evaluation\" + 0.028*\"succession\" + 0.019*\"plan\" + 0.019*\"development\" + 0.018*\"session\" + 0.018*\"senior\" + 0.016*\"charter\" + 0.015*\"annually\" + 0.014*\"report\" + 0.012*\"planning\"\n",
      "2020-11-17 23:52:56.160 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.027*\"candidate\" + 0.021*\"change\" + 0.018*\"experience\" + 0.015*\"recommend\" + 0.014*\"public\" + 0.014*\"membership\" + 0.012*\"nominee\" + 0.011*\"election\" + 0.011*\"criterion\" + 0.010*\"nomination\"\n",
      "2020-11-17 23:52:56.162 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.024*\"corporation\" + 0.022*\"transaction\" + 0.019*\"information\" + 0.016*\"person\" + 0.013*\"party\" + 0.012*\"discover\" + 0.012*\"guideline\" + 0.011*\"related\" + 0.011*\"organization\" + 0.010*\"confidential\"\n",
      "2020-11-17 23:52:56.163 INFO    gensim.models.ldamodel: topic diff=0.178604, rho=0.304855\n",
      "2020-11-17 23:52:57.869 INFO    gensim.models.ldamodel: -6.352 per-word bound, 81.7 perplexity estimate based on a held-out corpus of 1520 documents with 51615 words\n"
     ]
    }
   ],
   "source": [
    "num_topics = 8\n",
    "lda_model =  LdaMulticore(\n",
    "    corpus=bow_corpus, \n",
    "    num_topics = num_topics, \n",
    "    id2word = dictionary,                                    \n",
    "    passes = 10,\n",
    "    workers = 2\n",
    "    )"
   ]
  },
  {
   "source": [
    "### 2.2.1 Normalized Point-wise Mutual Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics_d = {}\n",
    "lda_topics_l = []\n",
    "for i in range(num_topics):\n",
    "    t = [w[0] for w in lda_model.show_topic(i)[0:10]]\n",
    "    lda_topics_d[i+1] = t\n",
    "    lda_topics_l.append(t)"
   ]
  },
  {
   "source": [
    "### 2.2.2 External Word Embeddings Topic Coherence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             0            1            2             3          4  \\\n",
       "1  corporation  transaction  information        person      party   \n",
       "2      advisor         plan  shareholder     financial     family   \n",
       "3        stock    guideline    ownership         share      fifth   \n",
       "4    candidate       change   experience     recommend     public   \n",
       "5  resignation     election         vote  independence   majority   \n",
       "6   evaluation   succession         plan   development    session   \n",
       "7      program  orientation    education      continue  financial   \n",
       "8       agenda     material      advance      schedule       item   \n",
       "\n",
       "               5            6         7             8             9  \n",
       "1       discover    guideline   related  organization  confidential  \n",
       "2        receive    immediate       fee         legal          deem  \n",
       "3    requirement      conduct     value       require          code  \n",
       "4     membership      nominee  election     criterion    nomination  \n",
       "5   relationship      receive    family      exchange        accept  \n",
       "6         senior      charter  annually        report      planning  \n",
       "7        advisor   accounting   outside         limit     operation  \n",
       "8  communication  stockholder   session        expect   information  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>corporation</td>\n      <td>transaction</td>\n      <td>information</td>\n      <td>person</td>\n      <td>party</td>\n      <td>discover</td>\n      <td>guideline</td>\n      <td>related</td>\n      <td>organization</td>\n      <td>confidential</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>advisor</td>\n      <td>plan</td>\n      <td>shareholder</td>\n      <td>financial</td>\n      <td>family</td>\n      <td>receive</td>\n      <td>immediate</td>\n      <td>fee</td>\n      <td>legal</td>\n      <td>deem</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>stock</td>\n      <td>guideline</td>\n      <td>ownership</td>\n      <td>share</td>\n      <td>fifth</td>\n      <td>requirement</td>\n      <td>conduct</td>\n      <td>value</td>\n      <td>require</td>\n      <td>code</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>candidate</td>\n      <td>change</td>\n      <td>experience</td>\n      <td>recommend</td>\n      <td>public</td>\n      <td>membership</td>\n      <td>nominee</td>\n      <td>election</td>\n      <td>criterion</td>\n      <td>nomination</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>resignation</td>\n      <td>election</td>\n      <td>vote</td>\n      <td>independence</td>\n      <td>majority</td>\n      <td>relationship</td>\n      <td>receive</td>\n      <td>family</td>\n      <td>exchange</td>\n      <td>accept</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>evaluation</td>\n      <td>succession</td>\n      <td>plan</td>\n      <td>development</td>\n      <td>session</td>\n      <td>senior</td>\n      <td>charter</td>\n      <td>annually</td>\n      <td>report</td>\n      <td>planning</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>program</td>\n      <td>orientation</td>\n      <td>education</td>\n      <td>continue</td>\n      <td>financial</td>\n      <td>advisor</td>\n      <td>accounting</td>\n      <td>outside</td>\n      <td>limit</td>\n      <td>operation</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>agenda</td>\n      <td>material</td>\n      <td>advance</td>\n      <td>schedule</td>\n      <td>item</td>\n      <td>communication</td>\n      <td>stockholder</td>\n      <td>session</td>\n      <td>expect</td>\n      <td>information</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# show topics\n",
    "# evert row is a topic\n",
    "pd.DataFrame.from_dict(lda_topics_d).T"
   ]
  },
  {
   "source": [
    "### 2.2.3 Rank-Biased Overlap "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:52:58.061 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-17 23:52:58.284 INFO    gensim.corpora.dictionary: built Dictionary(2853 unique tokens: ['activity', 'applicable', 'arena', 'assessment', 'background']...) from 1520 documents (total 94899 corpus positions)\n",
      "2020-11-17 23:52:58.288 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-11-17 23:53:03.185 INFO    gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (3501 virtual)\n",
      "2020-11-17 23:53:03.188 INFO    gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (7082 virtual)\n",
      "2020-11-17 23:53:03.194 INFO    gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (10724 virtual)\n",
      "2020-11-17 23:53:03.199 INFO    gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (13971 virtual)\n",
      "2020-11-17 23:53:03.204 INFO    gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (17522 virtual)\n",
      "2020-11-17 23:53:03.207 INFO    gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (21152 virtual)\n",
      "2020-11-17 23:53:03.303 INFO    gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (24774 virtual)\n",
      "2020-11-17 23:53:03.315 INFO    gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (28358 virtual)\n",
      "2020-11-17 23:53:03.336 INFO    gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (31253 virtual)\n",
      "2020-11-17 23:53:03.428 INFO    gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (34862 virtual)\n",
      "2020-11-17 23:53:03.456 INFO    gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (38693 virtual)\n",
      "2020-11-17 23:53:03.474 INFO    gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (42293 virtual)\n",
      "2020-11-17 23:53:03.568 INFO    gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (46221 virtual)\n",
      "2020-11-17 23:53:03.581 INFO    gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (49745 virtual)\n",
      "2020-11-17 23:53:03.591 INFO    gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (53317 virtual)\n",
      "2020-11-17 23:53:03.696 INFO    gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (56712 virtual)\n",
      "2020-11-17 23:53:03.715 INFO    gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (59904 virtual)\n",
      "2020-11-17 23:53:03.721 INFO    gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (63534 virtual)\n",
      "2020-11-17 23:53:03.826 INFO    gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (67182 virtual)\n",
      "2020-11-17 23:53:03.832 INFO    gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (70302 virtual)\n",
      "2020-11-17 23:53:03.860 INFO    gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (73900 virtual)\n",
      "2020-11-17 23:53:03.953 INFO    gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (77091 virtual)\n",
      "2020-11-17 23:53:03.973 INFO    gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (79908 virtual)\n",
      "2020-11-17 23:53:04.004 INFO    gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (81083 virtual)\n",
      "2020-11-17 23:53:04.223 INFO    gensim.topic_coherence.text_analysis: 3 accumulators retrieved from output queue\n",
      "2020-11-17 23:53:04.238 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 81095 virtual documents\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.022353241509189863"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "npmi = CoherenceNPMI(texts=text_cleaned, topics=lda_topics_l)\n",
    "npmi.score()"
   ]
  },
  {
   "source": [
    "## 3. Bert Topic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.1 Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:53:04.645 INFO    gensim.models.utils_any2vec: loading projection weights from C:\\Users\\Pieter-Jan/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2020-11-17 23:54:26.382 INFO    gensim.models.utils_any2vec: loaded (3000000, 300) matrix from C:\\Users\\Pieter-Jan/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.13298091"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "CoherenceWordEmbeddings(lda_topics_l).score()"
   ]
  },
  {
   "source": [
    "## 3.2 Evaluate topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9795098052311224"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "InvertedRBO(lda_topics_l).score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:54:49,596 - BERTopic - Reduced dimensionality with UMAP\n",
      "2020-11-17 23:54:49.596 INFO    BERTopic: Reduced dimensionality with UMAP\n",
      "2020-11-17 23:54:49,878 - BERTopic - Clustered UMAP embeddings with HDBSCAN\n",
      "2020-11-17 23:54:49.878 INFO    BERTopic: Clustered UMAP embeddings with HDBSCAN\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "with open('output/Cgovernance_processed_cleaned_pdfMiner.txt',\"r\") as fr:\n",
    "    docs = [doc for doc in fr.read().splitlines()] \n",
    "\n",
    "model = BERTopic(verbose=True)\n",
    "topics = model.fit_transform(docs, embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcis_b = model.get_topics()"
   ]
  },
  {
   "source": [
    "### 3.2.1 Normalized Point-wise Mutual Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract words for each topic\n",
    "topics_k = {}\n",
    "for k,v in topcis_b.items():\n",
    "    t_words = []\n",
    "    for w in v:\n",
    "        t_words.append(w[0])\n",
    "    # append the first 10 words\n",
    "    topics_k[k] = t_words[0:10]"
   ]
  },
  {
   "source": [
    "### 3.2.2 External Word Embeddings Topic Coherence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 0            1             2              3            4  \\\n",
       "-1       guideline         code      conflict        conduct      program   \n",
       " 0           stock        share     ownership         common         unit   \n",
       " 1    relationship     standard  independence  determination         york   \n",
       " 2          family    immediate          year        payment      current   \n",
       " 3      experience    candidate         skill      diversity   background   \n",
       " 4          public        serve        profit        service        audit   \n",
       " 5            vote  resignation      election       majority       accept   \n",
       " 6          change   retirement         limit           term  resignation   \n",
       " 7   communication       access   information   confidential      contact   \n",
       " 8          agenda         lead       session       chairman         item   \n",
       " 9         charter        audit         stand     assignment        chair   \n",
       " 10        oversee         risk          long      oversight     strategy   \n",
       " 11   compensation         form           pay        receive       equity   \n",
       " 12     evaluation         self   performance     assessment       annual   \n",
       " 13     succession         plan      planning    development        chief   \n",
       "\n",
       "               5             6          7           8              9  \n",
       "-1    evaluation      business     policy   education        advisor  \n",
       " 0         value      retainer      equal      salary            own  \n",
       " 1      exchange      material       list   determine  affirmatively  \n",
       " 2        fiscal  organization    partner       gross     charitable  \n",
       " 3       nominee     criterion    diverse     ability      integrity  \n",
       " 4        notify    invitation     accept       limit        ability  \n",
       " 5        tender          cast      offer    decision         reject  \n",
       " 6         offer        resign     retire      accept     occupation  \n",
       " 7       advisor     secretary    outside      senior        request  \n",
       " 8      schedule      material    advance     preside          chair  \n",
       " 9   requirement         forth       rule  applicable     nominating  \n",
       " 10    guideline       monitor  financial      manage       business  \n",
       " 11    incentive       service   employee  comparable          award  \n",
       " 12       result       process     report  individual  effectiveness  \n",
       " 13       senior     emergency  successor       event       annually  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1</th>\n      <td>guideline</td>\n      <td>code</td>\n      <td>conflict</td>\n      <td>conduct</td>\n      <td>program</td>\n      <td>evaluation</td>\n      <td>business</td>\n      <td>policy</td>\n      <td>education</td>\n      <td>advisor</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>stock</td>\n      <td>share</td>\n      <td>ownership</td>\n      <td>common</td>\n      <td>unit</td>\n      <td>value</td>\n      <td>retainer</td>\n      <td>equal</td>\n      <td>salary</td>\n      <td>own</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>relationship</td>\n      <td>standard</td>\n      <td>independence</td>\n      <td>determination</td>\n      <td>york</td>\n      <td>exchange</td>\n      <td>material</td>\n      <td>list</td>\n      <td>determine</td>\n      <td>affirmatively</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>family</td>\n      <td>immediate</td>\n      <td>year</td>\n      <td>payment</td>\n      <td>current</td>\n      <td>fiscal</td>\n      <td>organization</td>\n      <td>partner</td>\n      <td>gross</td>\n      <td>charitable</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>experience</td>\n      <td>candidate</td>\n      <td>skill</td>\n      <td>diversity</td>\n      <td>background</td>\n      <td>nominee</td>\n      <td>criterion</td>\n      <td>diverse</td>\n      <td>ability</td>\n      <td>integrity</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>public</td>\n      <td>serve</td>\n      <td>profit</td>\n      <td>service</td>\n      <td>audit</td>\n      <td>notify</td>\n      <td>invitation</td>\n      <td>accept</td>\n      <td>limit</td>\n      <td>ability</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>vote</td>\n      <td>resignation</td>\n      <td>election</td>\n      <td>majority</td>\n      <td>accept</td>\n      <td>tender</td>\n      <td>cast</td>\n      <td>offer</td>\n      <td>decision</td>\n      <td>reject</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>change</td>\n      <td>retirement</td>\n      <td>limit</td>\n      <td>term</td>\n      <td>resignation</td>\n      <td>offer</td>\n      <td>resign</td>\n      <td>retire</td>\n      <td>accept</td>\n      <td>occupation</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>communication</td>\n      <td>access</td>\n      <td>information</td>\n      <td>confidential</td>\n      <td>contact</td>\n      <td>advisor</td>\n      <td>secretary</td>\n      <td>outside</td>\n      <td>senior</td>\n      <td>request</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>agenda</td>\n      <td>lead</td>\n      <td>session</td>\n      <td>chairman</td>\n      <td>item</td>\n      <td>schedule</td>\n      <td>material</td>\n      <td>advance</td>\n      <td>preside</td>\n      <td>chair</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>charter</td>\n      <td>audit</td>\n      <td>stand</td>\n      <td>assignment</td>\n      <td>chair</td>\n      <td>requirement</td>\n      <td>forth</td>\n      <td>rule</td>\n      <td>applicable</td>\n      <td>nominating</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>oversee</td>\n      <td>risk</td>\n      <td>long</td>\n      <td>oversight</td>\n      <td>strategy</td>\n      <td>guideline</td>\n      <td>monitor</td>\n      <td>financial</td>\n      <td>manage</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>compensation</td>\n      <td>form</td>\n      <td>pay</td>\n      <td>receive</td>\n      <td>equity</td>\n      <td>incentive</td>\n      <td>service</td>\n      <td>employee</td>\n      <td>comparable</td>\n      <td>award</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>evaluation</td>\n      <td>self</td>\n      <td>performance</td>\n      <td>assessment</td>\n      <td>annual</td>\n      <td>result</td>\n      <td>process</td>\n      <td>report</td>\n      <td>individual</td>\n      <td>effectiveness</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>succession</td>\n      <td>plan</td>\n      <td>planning</td>\n      <td>development</td>\n      <td>chief</td>\n      <td>senior</td>\n      <td>emergency</td>\n      <td>successor</td>\n      <td>event</td>\n      <td>annually</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "topics_bert = list(topics_k.values())\n",
    "pd.DataFrame.from_dict(topics_k).T"
   ]
  },
  {
   "source": [
    "### 3.2.3 Rank-Biased Overlap "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:54:50.443 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-17 23:54:50.671 INFO    gensim.corpora.dictionary: built Dictionary(2853 unique tokens: ['activity', 'applicable', 'arena', 'assessment', 'background']...) from 1520 documents (total 94899 corpus positions)\n",
      "2020-11-17 23:54:50.679 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-11-17 23:54:56.497 INFO    gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (3501 virtual)\n",
      "2020-11-17 23:54:56.501 INFO    gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (7082 virtual)\n",
      "2020-11-17 23:54:56.511 INFO    gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (10724 virtual)\n",
      "2020-11-17 23:54:56.521 INFO    gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (13971 virtual)\n",
      "2020-11-17 23:54:56.530 INFO    gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (17522 virtual)\n",
      "2020-11-17 23:54:56.540 INFO    gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (21152 virtual)\n",
      "2020-11-17 23:54:56.752 INFO    gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (24774 virtual)\n",
      "2020-11-17 23:54:56.760 INFO    gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (28358 virtual)\n",
      "2020-11-17 23:54:56.837 INFO    gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (31253 virtual)\n",
      "2020-11-17 23:54:56.986 INFO    gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (34862 virtual)\n",
      "2020-11-17 23:54:57.052 INFO    gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (38651 virtual)\n",
      "2020-11-17 23:54:57.075 INFO    gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (42231 virtual)\n",
      "2020-11-17 23:54:57.205 INFO    gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (46151 virtual)\n",
      "2020-11-17 23:54:57.261 INFO    gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (49672 virtual)\n",
      "2020-11-17 23:54:57.279 INFO    gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (53208 virtual)\n",
      "2020-11-17 23:54:57.432 INFO    gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (56602 virtual)\n",
      "2020-11-17 23:54:57.516 INFO    gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (59837 virtual)\n",
      "2020-11-17 23:54:57.542 INFO    gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (63364 virtual)\n",
      "2020-11-17 23:54:57.670 INFO    gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (67064 virtual)\n",
      "2020-11-17 23:54:57.730 INFO    gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (70133 virtual)\n",
      "2020-11-17 23:54:57.736 INFO    gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (73734 virtual)\n",
      "2020-11-17 23:54:57.865 INFO    gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (76940 virtual)\n",
      "2020-11-17 23:54:57.904 INFO    gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (79859 virtual)\n",
      "2020-11-17 23:54:57.925 INFO    gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (81177 virtual)\n",
      "2020-11-17 23:54:58.321 INFO    gensim.topic_coherence.text_analysis: 3 accumulators retrieved from output queue\n",
      "2020-11-17 23:54:58.353 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 81190 virtual documents\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.15455125119020208"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "npmi = CoherenceNPMI(texts=text_cleaned, topics=topics_bert)\n",
    "npmi.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-17 23:54:58.887 INFO    gensim.models.utils_any2vec: loading projection weights from C:\\Users\\Pieter-Jan/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2020-11-17 23:56:21.814 INFO    gensim.models.utils_any2vec: loaded (3000000, 300) matrix from C:\\Users\\Pieter-Jan/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1545211"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "CoherenceWordEmbeddings(topics_bert).score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.992035617275102"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "InvertedRBO(topics_bert).score()"
   ]
  }
 ]
}