{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"C:\\\\Users\\\\Pieter-Jan\\\\Documents\\\\Work\\\\Candriam\\\\nlp\\\\ESG\\\\topic_sentiment_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-06 15:51:30.004 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-11-06 15:51:30.006 INFO    gensim.corpora.dictionary: built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "import modules.preprocessing as preprocess\n",
    "\n",
    "from contextualized_topic_models.models.ctm import CTM\n",
    "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file, TextHandler\n",
    "from contextualized_topic_models.datasets.dataset import CTMDataset\n",
    "from contextualized_topic_models.evaluation.measures import CoherenceNPMI, InvertedRBO\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import ldamodel \n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "doc = \"https://www.nvidia.com/content/dam/en-zz/Solutions/documents/FY2019-NVIDIA-CSR-Social-Responsibility.pdf\"\n",
    "doc_txt = preprocess.extract_content(url=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_proc = preprocess.extract_statements(doc_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(text_proc, columns=[\"doc\"]).to_csv('output/test.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextualized_topic_models.utils.preprocessing import SimplePreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [line.strip() for line in open(\"output/test.txt\").readlines()]\n",
    "sp = SimplePreprocessing(documents)\n",
    "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(preprocessed_documents, columns=[\"doc\"]).to_csv('output/test_processed.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = TextHandler('output/test_processed.txt')\n",
    "handler.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-06 16:21:12.929 INFO    root: Load pretrained SentenceTransformer: distilbert-base-nli-mean-tokens\n",
      "2020-11-06 16:21:12.931 INFO    root: Did not find folder distilbert-base-nli-mean-tokens. Assume to download model from server.\n",
      "2020-11-06 16:21:12.933 INFO    root: Load SentenceTransformer from folder: C:\\Users\\Pieter-Jan/.cache\\torch\\sentence_transformers\\sbert.net_models_distilbert-base-nli-mean-tokens\n",
      "2020-11-06 16:21:14.784 INFO    root: Use pytorch device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9da8c03b234969927a6ec8d435d452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_bert = bert_embeddings_from_file('output/test_processed.txt', \"distilbert-base-nli-mean-tokens\", batch_size=50)\n",
    "with open(\"saved_embeddings\", \"wb\") as filino:\n",
    "        pickle.dump(training_bert, filino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CTMDataset(handler.bow, training_bert, handler.idx2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n",
      "Epoch: [1/50]\tSamples: [197/9850]\tTrain Loss: 546.7924618793623\tTime: 0:00:07.156486\n",
      "Epoch: [2/50]\tSamples: [394/9850]\tTrain Loss: 543.0474958855489\tTime: 0:00:06.780657\n",
      "Epoch: [3/50]\tSamples: [591/9850]\tTrain Loss: 542.0321949605409\tTime: 0:00:06.640990\n",
      "Epoch: [4/50]\tSamples: [788/9850]\tTrain Loss: 539.687543375238\tTime: 0:00:06.570036\n",
      "Epoch: [5/50]\tSamples: [985/9850]\tTrain Loss: 535.8946923580266\tTime: 0:00:06.586986\n",
      "Epoch: [6/50]\tSamples: [1182/9850]\tTrain Loss: 534.4415524865165\tTime: 0:00:06.443135\n",
      "Epoch: [7/50]\tSamples: [1379/9850]\tTrain Loss: 531.1999784363103\tTime: 0:00:06.536918\n",
      "Epoch: [8/50]\tSamples: [1576/9850]\tTrain Loss: 527.4485086353902\tTime: 0:00:06.430604\n",
      "Epoch: [9/50]\tSamples: [1773/9850]\tTrain Loss: 526.8310057354457\tTime: 0:00:06.536879\n",
      "Epoch: [10/50]\tSamples: [1970/9850]\tTrain Loss: 525.4143896732234\tTime: 0:00:06.539072\n",
      "Epoch: [11/50]\tSamples: [2167/9850]\tTrain Loss: 520.397173421637\tTime: 0:00:06.501975\n",
      "Epoch: [12/50]\tSamples: [2364/9850]\tTrain Loss: 519.7076880750317\tTime: 0:00:05.538617\n",
      "Epoch: [13/50]\tSamples: [2561/9850]\tTrain Loss: 518.4743193805521\tTime: 0:00:05.288874\n",
      "Epoch: [14/50]\tSamples: [2758/9850]\tTrain Loss: 514.9067017221208\tTime: 0:00:05.357865\n",
      "Epoch: [15/50]\tSamples: [2955/9850]\tTrain Loss: 516.1453380294257\tTime: 0:00:05.586984\n",
      "Epoch: [16/50]\tSamples: [3152/9850]\tTrain Loss: 512.0973811270621\tTime: 0:00:05.562094\n",
      "Epoch: [17/50]\tSamples: [3349/9850]\tTrain Loss: 510.48542715934326\tTime: 0:00:05.465987\n",
      "Epoch: [18/50]\tSamples: [3546/9850]\tTrain Loss: 509.3678158213039\tTime: 0:00:05.167037\n",
      "Epoch: [19/50]\tSamples: [3743/9850]\tTrain Loss: 508.59253549333755\tTime: 0:00:05.296919\n",
      "Epoch: [20/50]\tSamples: [3940/9850]\tTrain Loss: 503.5074506265863\tTime: 0:00:05.440602\n",
      "Epoch: [21/50]\tSamples: [4137/9850]\tTrain Loss: 506.1124298560438\tTime: 0:00:05.746095\n",
      "Epoch: [22/50]\tSamples: [4334/9850]\tTrain Loss: 503.5388865204632\tTime: 0:00:06.524930\n",
      "Epoch: [23/50]\tSamples: [4531/9850]\tTrain Loss: 505.67543796597397\tTime: 0:00:06.561015\n",
      "Epoch: [24/50]\tSamples: [4728/9850]\tTrain Loss: 503.76548248136106\tTime: 0:00:06.567035\n",
      "Epoch: [25/50]\tSamples: [4925/9850]\tTrain Loss: 500.4954108998255\tTime: 0:00:06.645055\n",
      "Epoch: [26/50]\tSamples: [5122/9850]\tTrain Loss: 500.8058202133566\tTime: 0:00:06.601081\n",
      "Epoch: [27/50]\tSamples: [5319/9850]\tTrain Loss: 500.407004109494\tTime: 0:00:06.790880\n",
      "Epoch: [28/50]\tSamples: [5516/9850]\tTrain Loss: 500.6510251427665\tTime: 0:00:06.510992\n",
      "Epoch: [29/50]\tSamples: [5713/9850]\tTrain Loss: 499.3078538923699\tTime: 0:00:07.893555\n",
      "Epoch: [30/50]\tSamples: [5910/9850]\tTrain Loss: 497.9779034144987\tTime: 0:00:07.257942\n",
      "Epoch: [31/50]\tSamples: [6107/9850]\tTrain Loss: 499.4587005770146\tTime: 0:00:06.625062\n",
      "Epoch: [32/50]\tSamples: [6304/9850]\tTrain Loss: 495.7259193071859\tTime: 0:00:06.841469\n",
      "Epoch: [33/50]\tSamples: [6501/9850]\tTrain Loss: 496.89909060715416\tTime: 0:00:06.292953\n",
      "Epoch: [34/50]\tSamples: [6698/9850]\tTrain Loss: 496.13659606004126\tTime: 0:00:05.980675\n",
      "Epoch: [35/50]\tSamples: [6895/9850]\tTrain Loss: 494.3046639534423\tTime: 0:00:05.507386\n",
      "Epoch: [36/50]\tSamples: [7092/9850]\tTrain Loss: 495.69888290172906\tTime: 0:00:05.431153\n",
      "Epoch: [37/50]\tSamples: [7289/9850]\tTrain Loss: 495.35990665648796\tTime: 0:00:05.486363\n",
      "Epoch: [38/50]\tSamples: [7486/9850]\tTrain Loss: 492.88330573842006\tTime: 0:00:05.427522\n",
      "Epoch: [39/50]\tSamples: [7683/9850]\tTrain Loss: 491.49454463435916\tTime: 0:00:05.969644\n",
      "Epoch: [40/50]\tSamples: [7880/9850]\tTrain Loss: 492.9081163745241\tTime: 0:00:06.640448\n",
      "Epoch: [41/50]\tSamples: [8077/9850]\tTrain Loss: 492.0373237726047\tTime: 0:00:18.232644\n",
      "Epoch: [42/50]\tSamples: [8274/9850]\tTrain Loss: 494.8734930203046\tTime: 0:00:10.901444\n",
      "Epoch: [43/50]\tSamples: [8471/9850]\tTrain Loss: 490.23852043345494\tTime: 0:00:08.105696\n",
      "Epoch: [44/50]\tSamples: [8668/9850]\tTrain Loss: 491.74302650103107\tTime: 0:00:08.041074\n",
      "Epoch: [45/50]\tSamples: [8865/9850]\tTrain Loss: 490.1149741235723\tTime: 0:00:09.492006\n",
      "Epoch: [46/50]\tSamples: [9062/9850]\tTrain Loss: 490.93192566227793\tTime: 0:00:08.384884\n",
      "Epoch: [47/50]\tSamples: [9259/9850]\tTrain Loss: 489.7445421557741\tTime: 0:00:08.219149\n",
      "Epoch: [48/50]\tSamples: [9456/9850]\tTrain Loss: 492.1039369844543\tTime: 0:00:08.497369\n",
      "Epoch: [49/50]\tSamples: [9653/9850]\tTrain Loss: 488.4436642409581\tTime: 0:00:08.550695\n",
      "Epoch: [50/50]\tSamples: [9850/9850]\tTrain Loss: 486.94045447335026\tTime: 0:00:09.019365\n"
     ]
    }
   ],
   "source": [
    "ctm = CTM(input_size=len(handler.vocab), bert_input_size=768, inference_type=\"combined\", n_components=10, num_epochs=50)\n",
    "ctm.fit(training_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['emissions',\n",
       "  'scope',\n",
       "  'ghg',\n",
       "  'energy',\n",
       "  'waste',\n",
       "  'data',\n",
       "  'metric',\n",
       "  'gas',\n",
       "  'environment',\n",
       "  'total'],\n",
       " ['compliance',\n",
       "  'report',\n",
       "  'code',\n",
       "  'standards',\n",
       "  'rba',\n",
       "  'presented',\n",
       "  'signicant',\n",
       "  'assessment',\n",
       "  'chain',\n",
       "  'disclosures'],\n",
       " ['use',\n",
       "  'materials',\n",
       "  'silicon',\n",
       "  'using',\n",
       "  'reducing',\n",
       "  'include',\n",
       "  'efcient',\n",
       "  'certications',\n",
       "  'valley',\n",
       "  'new'],\n",
       " ['practices',\n",
       "  'provide',\n",
       "  'around',\n",
       "  'industry',\n",
       "  'improve',\n",
       "  'define',\n",
       "  'iso',\n",
       "  'become',\n",
       "  'users',\n",
       "  'teams'],\n",
       " ['meetings',\n",
       "  'oversees',\n",
       "  'subject',\n",
       "  'hold',\n",
       "  'committee',\n",
       "  'reports',\n",
       "  'commission',\n",
       "  'staff',\n",
       "  'respond',\n",
       "  'matter'],\n",
       " ['requirements',\n",
       "  'risk',\n",
       "  'rba',\n",
       "  'minerals',\n",
       "  'compliance',\n",
       "  'priority',\n",
       "  'validated',\n",
       "  'suppliers',\n",
       "  'transparency',\n",
       "  'critical'],\n",
       " ['nvidia',\n",
       "  'gpu',\n",
       "  'computing',\n",
       "  'platform',\n",
       "  'gpus',\n",
       "  'supercomputers',\n",
       "  'worlds',\n",
       "  'computer',\n",
       "  'cars',\n",
       "  'architecture'],\n",
       " ['women',\n",
       "  'minority',\n",
       "  'recruiting',\n",
       "  'female',\n",
       "  'technical',\n",
       "  'conference',\n",
       "  'hopper',\n",
       "  'underrepresented',\n",
       "  'providing',\n",
       "  'gender'],\n",
       " ['best',\n",
       "  'fortune',\n",
       "  'benets',\n",
       "  'talent',\n",
       "  'companies',\n",
       "  'retain',\n",
       "  'working',\n",
       "  'places',\n",
       "  'attract',\n",
       "  'great'],\n",
       " ['executive',\n",
       "  'governance',\n",
       "  'rba',\n",
       "  'approach',\n",
       "  'stakeholder',\n",
       "  'board',\n",
       "  'standards',\n",
       "  'chain',\n",
       "  'description',\n",
       "  'economic']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctm.get_topic_lists(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
